<!DOCTYPE html><!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Thu Dec 03 2020 15:46:56 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="5fc8b1bb8d6164320dba8754" data-wf-site="5fc8b1bb8d61644687ba8753">
<head>
  <meta charset="utf-8">
  <title>SRGAN</title>
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/srgan.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
</head>
<body>
  <header id="nav" class="sticky-nav-2">
    <nav class="w-container">
      <ul role="list" class="nav-grid-2 w-list-unstyled">
        <li id="w-node-2fcc22990398-22990395">
          <a href="#" class="nav-logo-link w-inline-block"></a>
        </li>
        <li>
          <a href="index.html" aria-current="page" class="nav-link-4 w--current">Home</a>
        </li>
        <li id="w-node-2fcc2299039d-22990395">
          <a href="convert.html" class="nav-link-4">Convert</a>
        </li>
        <li id="w-node-2fcc229903a0-22990395">
          <a href="about-us.html" class="nav-link-4">About Us</a>
        </li>
      </ul>
    </nav>
  </header>
  <header id="hero-overlay" class="hero-overlay">
    <div class="centered-container w-container">
      <h1 class="heading">SRGAN</h1>
      <p class="paragraph"><strong>SRGAN</strong> is a generative adversarial network for single image super-resolution.<br>Essentially we make a low resolution which looks bad into <br>an image that looks absolutely <strong>AMAZING !!</strong></p>
      <div>
        <a href="convert.html" class="button w-button">Try It Out</a>
      </div>
    </div>
  </header>
  <section id="cards-section" class="cards-section">
    <div class="centered-container w-container">
      <h2 class="heading-2">What is SRGAN ?</h2>
      <p class="paragraph-3">Super-resolution GAN applies a deep network in combination with an adversary network to produce higher resolution images. As shown below, SRGAN is more appealing to a human with more details compared with the similar design without GAN (SRResNet). During the training, A high-resolution image (HR) is downsampled to a low-resolution image (LR). A GAN generator upsamples LR images to super-resolution images (SR). We use a discriminator to distinguish the HR images and backpropagate the GAN loss to train the discriminator and the generator.</p>
      <div class="w-layout-grid grid">
        <h4 id="w-node-745061d63f56-0dba8754" class="heading-10">Low Resolution Images</h4>
        <h4 id="w-node-577174f52b91-0dba8754" class="heading-11">Genereated Using SRGAN from LR Images</h4><img src="images/input2.PNG" loading="lazy" width="467" id="w-node-02ae4dd8c235-0dba8754" alt=""><img src="images/output2.PNG" loading="lazy" width="461" id="w-node-d25b4fc0a328-0dba8754" alt=""><img src="images/input.PNG" loading="lazy" width="555" id="w-node-fa967d7c94f3-0dba8754" alt=""><img src="images/output.PNG" loading="lazy" width="580" id="w-node-86f9f8f5ed83-0dba8754" alt="" class="image-4">
      </div>
    </div>
  </section>
  <div class="container-2 w-container">
    <h1>How does it work?</h1>
    <div class="div-block"><img src="images/srgan.PNG" loading="lazy" width="860" sizes="(max-width: 479px) 87vw, (max-width: 767px) 88vw, (max-width: 991px) 698px, 860px" srcset="images/srgan-p-500.png 500w, images/srgan.PNG 776w" alt="" class="image-2"></div>
    <h3 class="heading-7">Generator Architecture:</h3>
    <p class="paragraph-2"><strong class="bold-text">The generator architecture contains residual network instead of deep convolution networks because residual networks are easy to train and allows them to be substantially deeper in order to generate better results. This is because the residual network used a type of connections called skip connections.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.<br><br>There are B residual blocks (16), originated by ResNet. Within the residual block, two convolutional layers are used, with small 3×3 kernels and 64 feature maps followed by batch-normalization layers and ParametricReLU as the activation function.<br><br>The resolution of the input image is increased with two trained sub-pixel convolution layers.<br><br>This generator architecture also uses parametric ReLU as an activation function which instead of using a fixed value for a parameter of the rectifier (alpha) like LeakyReLU. It adaptively learns the parameters of rectifier and   improves the accuracy at negligible extra computational cost</strong></p>
    <h3 class="heading-9">Discriminator Architecture:</h3>
    <p class="paragraph-4">The task of the discriminator is to discriminate between real HR images and generated SR images.   The discriminator architecture used in this paper is similar to DC- GAN architecture with LeakyReLU as activation. The network contains eight convolutional layers with of 3×3 filter kernels, increasing by a factor of 2 from 64 to 512 kernels. Strided convolutions are used to reduce the image resolution each time the number of features is doubled. The resulting 512 feature maps are followed by two dense layers and a leakyReLU applied between and a final sigmoid activation function to obtain a probability for sample classification.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.</p>
  </div>
  <footer id="footer" class="footer">
    <div class="w-container">
      <div class="text-block">Data Science and Machine Learning Self Study @RV College of Engineering</div>
    </div>
  </footer>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=5fc8b1bb8d61644687ba8753" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
</body>
</html>